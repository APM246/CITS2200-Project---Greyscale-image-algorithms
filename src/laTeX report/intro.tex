\documentclass[12pt]{article}
\author{Arun Muthu}
\title{CITS2200 Project Report}
\usepackage{amsmath}
\usepackage[big]{titlesec}
\usepackage{listings}
\usepackage{color}
\usepackage{amssymb}
\definecolor{dkgreen}{rgb}{0,0.6,0}
\definecolor{gray}{rgb}{0.5,0.5,0.5}
\definecolor{mauve}{rgb}{0.58,0,0.82}
\lstset{frame=tb,
	language=Java,
	aboveskip=3mm,
	belowskip=3mm,
	showstringspaces=false,
	columns=flexible,
	basicstyle={\small\ttfamily},
	numbers=none,
	numberstyle=\tiny\color{gray},
	keywordstyle=\color{blue},
	commentstyle=\color{dkgreen},
	stringstyle=\color{mauve},
	breaklines=true,
	breakatwhitespace=true,
	tabsize=3
}
\addtolength{\topmargin}{-.875in}
\usepackage{tikz}
\usetikzlibrary{trees}
\begin{document}
	\maketitle
	\newpage
	\tableofcontents
	\newpage
    %\part*{1) floodFillCount} 
    \section{FloodFill Count}
    \subsection*{Correctness}
    \begin{flushleft}
    floodFillCount uses a non-recursive depth-first search to search for every contiguous pixel matching the brightness of the original pixel. The inductive step is as follows: \newline\newline
    \textit{Remove the top-most pixel from the stack and check the pixels above, below, left and right. For any pixel that matches the brightness of the original pixel, convert it to black and push it onto the stack. Increase the count by 1 after this is done.} \newline
    
    Since the first original pixel is converted to black and pushed onto the stack, the algorithm will
    convert its matching neighbours to black, the neighbours' matching neighbours to black and so on. Count is incremented by one for every pixel removed from the stack, and hence once the stack is empty (all suitable pixels processed) the algorithm will return a correct count.\newline
    
    The algorithm does take into account the scenario where the starting pixel is black, in which case 0 is immediately returned.
    
    \subsection*{Time Complexity}
    The algorithm first creates an empty stack and pushes the original pixel onto it. The algorithm then uses a while loop to perform the depth-first search, stopping when the stack becomes empty. For every iteration of the while loop, the current pixel's 4 neighbours are examined with array accesses and count is incremented by 1. Let these constant time operations be denoted by the variable c. In the worst-case scenario, every pixel in the image matches the brightness of the original pixel and thus the stack will remain non-empty until every pixel in the image is examined. In other words, the while loop will have to execute p times to examine each pixel.
	\begin{equation}
		\begin{aligned}
             time &= p \times c\\
         		  &= \textbf{O(p)}
     	\end{aligned}
     \end{equation}
     Hence floodFillCount's worst-case complexity is \textbf{O(p)}.   
     
     \section{Brightest Square}
     \subsection*{Correctness} 
     The algorithm starts by finding the sum of every possible subarray of length k in each row and placing the sums in a 2-dimensional integer array \textit{row\_sums}.\newline \newline
     \begin{tabular}{|c | c | c | c | c|}
     	\hline
     	a1 & a2 & a3 & a4 & a5\\ \hline
     	b1 & b2 & b3 & b4 & b5 \\ \hline
     	c1 & c2 & c3 & c4 & c5\\ \hline
     	d1 & d2 & d3 & d4 & d5\\ \hline
     \end{tabular}
     $\longrightarrow$
     \begin{tabular}{|c | c | c|}
     	\hline
     	a1+a2+a3 & a2+a3+a4 & a3+a4+a5 \\ \hline
     	b1+b2+b3 & b2+b3+b4 & b3+b4+b5 \\ \hline
     	c1+c2+c3 & c2+c3+c4 & c3+c4+c5 \\ \hline
     	d1+d2+d3 & d2+d3+d4 & d3+d4+d5 \\ \hline
     \end{tabular} \newline \newline
      It then finds the sum of every possible subcolumn of length k from each column in \textit{row\_sums}. The maximum of these sums is the brightness of the brightest square and is the returned answer. \newline
   	  $$max(\sum\limits_{i=0}^{C-1}\sum\limits_{n=0}^{C-k+1}\sum\limits_{j=n}^{k+n-1} row\_sums[j][i])\newline$$
   	  
       This is because the sum of each subcolumn represents the sum of one k*k square in the image. For example, the sum of the first subcolumn (row 0 to k-1) in the left-most column of row\_sums would represent the sum of the top-left most square, the sum of the 2nd subcolumn (row 1 to k) would represent the square one row below, and so on.\newline
       
       The algorithm is correct because it works under the same principle as a brute force solution, i.e. it finds the sum of every possible k*k square and returns the largest sum.
       
       \subsection*{Time Complexity}
       The algorithm is broken down into 2 main parts, calculating row\_sums and calculating the sums of every possible square. The first stage is as follows: \newline
       \begin{lstlisting}
       	for (int i = 0; i < n_rows; i++) {
       		int row_sum = 0;
       		for (int j = 0; j < k; j++) row_sum += image[i][j];
       		
       		row_sums[i][0] = row_sum;
       		for (int j = 1; j < n_cols - k + 1; j++) {
       			row_sum += image[i][j + k - 1] - image[i][j-1];
       			row_sums[i][j] = row_sum;
       		}
       	}
       	\end{lstlisting}
       \begin{equation}
       \begin{aligned}
       time_1 &= R(k + (C-k))\\
       &= R*C\\
       &= \textbf{O(p)}
       \end{aligned}
       \end{equation}
       In the 2nd stage: 
       \begin{lstlisting}
       for (int i = 0; i < n_cols - k + 1; i++) {
       	int current_sum = 0;
       	for (int j = 0; j < k; j++) current_sum += row_sums[j][i];
       	
       	max_sum = Math.max(current_sum, max_sum);
       	for (int m = 1; m < n_rows - k + 1; m++) {
       		current_sum += row_sums[m + k - 1][i]-row_sums[m - 1][i];
       		max_sum = Math.max(current_sum, max_sum);
       	}
       }
       \end{lstlisting}
       
       \begin{equation}
       \begin{aligned}
       time_2 &= (C-k+1)(k + (R-k))\\
       &= (C-k+1) \times R \\
       &=O(RC)\\
       &= \textbf{O(p)}
       \end{aligned}
       \end{equation}\newline
       
       Both stages are \textbf{O(p)}. $\therefore$ the algorithm's overall complexity is \textbf{O(p)}. The reason for the improved time efficiency compared to a brute force solution is mainly attributed to the way sums of subarrays and subcolumns are calculated. Instead of performing repetitive additions, the earliest element is subtracted from and the latest element is added to the previous sum.  
    
       \newpage 
       \section{Darkest Path}
       \subsection*{Correctness}
       The Darkest Path algorithm uses a Priority First Search to find the darkest path. The essence of the 
       search is based on one property. The brightness of a pixel (and thus path) is defined by the brightest pixel it has encountered in the path from the source to itself. This information is stored in the brightness\_key array and every update to it is based on one of two outcomes. The pixel's own brightness is the brightest it has encountered thus far or the brightest pixel in the path is. Due to the inequality $max\_brightness \lhd brightness\_key[neighbour]$, the algorithm prioritises \textbf{decreasing} the maximum brightness each pixel has encountered. \newline
       \begin{lstlisting}
       int max_brightness = Math.max(brightness_key[element], image[neighbour/n_cols][neighbour%n_cols]);
    
       if (max_brightness < brightness_key[neighbour]) {
           brightness_key[neighbour] =  max_brightness;
           pqueue.changePriority(neighbour, max_brightness);
       }
       \end{lstlisting}
		
        Hence the brightness\_key array always contains an upper bound on the lowest brightness a pixel has encountered. Due to the nature of a priority first search algorithm, pixels are dequeued only when the upper bound has converged to the lowest possible value and thus the algorithm is guaranteed to construct a search tree which emphasises on darkest paths. As a result once (vr, vc) is dequeued from the heap, 
        its value in the brightness\_key array will be the brightness of the darkest path from (ur, uc) to (vr, vc). 

		\subsection*{Time Complexity}
		Note: The height of a balanced binary tree is log n if there are n elements. 
		
		The priority first search is broken down into two main operations, dequeueing and updating the brightness\_key array. Each dequeue of a pixel from the priority queue is followed by a heapifyDown() operation, which ensures the heap property is still maintained. This is O(log p) in the worst case when the top element is continuously switched with the element below until it reaches the bottom of the heap. For each pixel that is dequeued, its 4 pixel neighbours (left, right, top and bottom in worst case) are examined. If a pixel's brightness\_key is updated, this requires a heapifyUp() operation which also restores the heap property. This is O(log p) in the worst-case scenario if an element at the lowest level is brough to the top of the tree.
		
		Hence, dequeueing and updating the key array are both O(log p) operations for a single pixel. In the overall worst case scenario, every pixel will be dequeued and every neighbour will have its priority be updated before (vr, vc) is dequeued and the algorithm stops. Therefore the following time complexity is achieved:
		
		\begin{equation}
		\begin{aligned}
		time &= \text{all pixels dequeued} + \text{all neighbours } (4 \times p) \text{ updated}\\
		     &= p \times log p + 4p \times log p\\
		     &= 5p \times log p\\
		     &= \textbf{O(p log p)}
		\end{aligned}
		\end{equation}\newline 
		
		\section{Brightest Pixels in Row Segments}
		\subsection*{Correctness}
		The algorithm makes use of a Binary tree in which every node stores the maximum of its two children. If this is repeated at every level until the root is created, then effectively each node stores the maximum element of a particular range of the array. This is demonstrated in the following diagram.\newline
		
		original array = [25,2,7,9,3,6]
	
		\begin{tikzpicture}[level distance=2cm,
		level 1/.style={sibling distance=7cm},
		level 2/.style={sibling distance=3.5cm},
		level 3/.style={sibling distance=1.6cm}]
		\node {25 (0,5)}
		child {node {25 (0,1)}
			child {node {0 (0,0)}
				child {node {0 (0,0)}}
				child {node {0 (0,0)}}
			}
			child {node {25 (0,1)} 
				child {node {25 (0,0)}}
				child {node {2 (1,1)}}
			}
		}
		child {node {9 (2,5)}
			child {node {9 (2,3)}
				child {node {7 (2,2)}}
				child {node {9 (3,3)}}}
			child {node {6 (4,5)}
				child {node {3 (4,4)}}
				child {node {6 (5,5)}}
			}
		};
		\end{tikzpicture}
		The 2-tuples next to each number denote the particular range of the array in which the node's value
		is the maximum element. Note that for an array whose length is not equal to $2^n$ (for some integer n), zeroes are added to the front of the array. This allows the algorithm to work and does not incorrectly change the results
		of any queries. The range of each node does not take into account the added zeroes (e.g. the root has range (0,5) which covers the 6 elements of the original array).  
		
		
		
		
		

        \newpage 
       \section{Appendix}
       \begin{thebibliography}{9}
    	\bibitem{geeksforgeeks1} 
    	GeeksforGeeks A computer science portal for geeks
    	\\\texttt{https://www.geeksforgeeks.org/print-maximum-sum-square-sub-matrix
    	-of-given-size/}
    	\bibitem{geeksforgeeks2} GeeksforGeeks A computer science portal for geeks
    	\\\texttt{https://www.geeksforgeeks.org/segment-tree-set-2-range-maximum-query-node
    	-update/}
       	\end{thebibliography}
       
     \end{flushleft}
	
\end{document}